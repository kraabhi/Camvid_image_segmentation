%reload_ext autoreload
%autoreload 2
%matplotlib inline

from fastai import *
from fastai.vision import *
from fastai.callbacks.hooks import *
from fastai.utils.mem import *

path = untar_data(URLs.CAMVID)
path_img = path/'images'
path_lbl = path/'labels'

fname = get_image_files(path_img)
fname[:3]

lname = get_image_files(path_lbl)
lname[:3]

open_image(fname[0]).show(figsize=(5,5))
get_fname = lambda x : path_lbl/'{}_P{}'.format(x.stem, x.suffix)
open_mask(get_fname(fname[0])).show(figsize=(5,5))

mask = open_mask(get_fname(fname[0]))
src_size = np.array(mask.size)
mask.data

code = np.loadtxt(path/'codes.txt', dtype='str')
size = src_size//2

free = gpu_mem_get_free_no_cache()
if free > 8200:
  bs =8
else:
  bs = 4
print('free is {} and using bs:{}'.format(free, bs))

src = (SegmentationItemList.from_folder(path_img)
       .split_by_fname_file('../valid.txt')
       .label_from_func(get_fname, classes=code))
     
data = (src.transform(get_transforms(), size=size, tfm_y=True)
        .databunch(bs=bs)
        .normalize(imagenet_stats))
     
data.show_batch(2, figsize=(10,12))

data.show_batch(2, figsize=(10,7), ds_type=DatasetType.Valid)

name2id = {v:k for k,v in enumerate(code)}
void_code = name2id['Void']

def acc_camvid(input, target):
    target = target.squeeze(1)
    mask = target != void_code
    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()
    
learn = unet_learner(data, models.resnet34, metrics= acc_camvid, wd = 1e-2)

learn.lr_find()
learn.recorder.plot()

learn.fit_one_cycle(10, slice(1e-3),pct_start=0.9)

/

learn.save("camvid_rsn36_v1")

learn.unfreeze()
learn.fit_one_cycle(10, slice(1e-5,(1e-3)/4), pct_start= 0.6) # pct_start signifies how much of number of epochs lr must increase

# epoch	train_loss	valid_loss	acc_camvid	time
0	0.366066	0.313555	0.912018	03:25
1	0.355876	0.318937	0.909805	03:25
2	0.344181	0.304597	0.908839	03:24
3	0.336337	0.293593	0.919696	03:25
4	0.328665	0.313158	0.912045	03:24
5	0.321979	0.285682	0.919035	03:25
6	0.304278	0.273869	0.926311	03:24
7	0.278107	0.279483	0.920879	03:25
8	0.260858	0.254494	0.928273	03:24
9	0.245937	0.248192	0.929464	03:25

learn.save("camvid_rsn36_v2")

learn.recorder.plot()
learn.freeze()
learn.fit_one_cycle(10,slice(1e-4),pct_start = 0.7)

# but as there is no improvement but actually overfitting so I stopped this trianing in between and verson 2 is the best model

learn.load("camvid_rsn36_v2")
learn.show_results(rows=3, figsize= (10,10))

learn.destroy()

size = src_size

free = gpu_mem_get_free_no_cache()
# the max size of bs depends on the available GPU RAM
if free > 8200: bs=3
else:           bs=1
print(f"using bs={bs}, have {free}MB of GPU RAM free")

# using this with full image size

# this Learner object self-destroyed - it still exists, but no longer usable
# using bs=3, have 9152MB of GPU RAM free

data = (src.transform(get_transforms(), size=size, tfm_y=True)
        .databunch(bs=bs)
        .normalize(imagenet_stats))

learn = unet_learner(data, models.resnet34, metrics=acc_camvid, wd=1e-3)
learn.load("camvid_rsn50_v2")

learn.lr_find()
learn.recorder.plot()
lr = ((1e-4)- (1e-5))/2
learn.fit_one_cycle(10, slice(lr), pct_start=0.7)

epoch	train_loss	valid_loss	acc_camvid	time
0	0.400996	0.301120	0.916617	14:01
1	0.360529	0.290095	0.917410	13:50
2	0.340898	0.274286	0.921597	13:49
3	0.327840	0.272843	0.922496	13:49
4	0.311188	0.273363	0.921526	13:49
5	0.310021	0.264988	0.925523	13:49
6	0.290089	0.258497	0.924960	13:50
7	0.278192	0.258185	0.926075	13:51
8	0.260849	0.257576	0.925466	13:51
9	0.249830	0.250741	0.927268	13:51

learn.save("camvid_rsn36_v3")

learn.export()
